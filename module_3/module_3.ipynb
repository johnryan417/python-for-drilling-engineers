{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c19a1e3",
   "metadata": {},
   "source": [
    "# Python for Drilling Engineers - Module 3\n",
    "## 1. 🔁 Recap & Today's Agenda\n",
    "Let's quickly review what we covered in Lesson 2:\n",
    "- Sorting, filtering, basic dataframe operations\n",
    "\n",
    "\n",
    "## Today's Objectives\n",
    "- DataFrames Continued...\n",
    "  - Grouping & Aggregation\n",
    "  - KPI Calculations with Groups\n",
    "  - Slicing with `.loc[]`\n",
    "- Data QA/QC Techniques\n",
    "  - Use .isna(), .duplicated() for checks\n",
    "  - Define your own thresholds (ex. ROP > 5000 fph = likely error)\n",
    "  - Remove null placeholders from datasets (ex. -999.99)\n",
    "  - IQR Outlier Removal\n",
    "- Pandas Profiling Library/Reports\n",
    "- **Bonus**: ML Concepts Overview\n",
    "\n",
    "...but first, let's load our dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c22d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "run_number = [4, 5, 6, 7, 10, 11, 13, 15, 16, 17, 18, 23, 26, 27, 28, 30, 31, 32, 33]\n",
    "start_time = [\"10/30/2020 3:20\", \"11/4/2020 8:49\", \"11/7/2020 16:38\", \"11/9/2020 22:41\", \"11/14/2020 11:43\",\n",
    "              \"11/15/2020 2:46\", \"11/20/2020 0:20\", \"11/24/2020 2:46\", \"11/25/2020 23:21\", \"11/26/2020 22:57\",\n",
    "              \"11/28/2020 14:49\", \"12/3/2020 23:23\", \"12/7/2020 3:30\", \"12/8/2020 20:34\", \"12/9/2020 13:17\",\n",
    "              \"12/12/2020 12:35\", \"12/13/2020 11:44\", \"12/17/2020 0:21\", \"12/18/2020 10:01\"]\n",
    "end_time = [\"10/31/2020 4:27\", \"11/7/2020 6:25\", \"11/8/2020 22:54\", \"11/10/2020 14:58\", \"11/14/2020 16:20\",\n",
    "            \"11/16/2020 13:28\", \"11/22/2020 6:35\", \"11/24/2020 18:30\", \"11/26/2020 10:40\", \"11/27/2020 19:57\",\n",
    "            \"11/29/2020 9:39\", \"12/5/2020 6:59\", \"12/7/2020 23:55\", \"12/9/2020 0:21\", \"12/9/2020 15:31\",\n",
    "            \"12/13/2020 0:54\", \"12/14/2020 8:19\", \"12/17/2020 18:38\", \"12/18/2020 23:58\"]\n",
    "run_duration = [25.11666667, 69.59722222, 30.26666667, 16.28333333, 4.616666667, 34.70277778, 54.25, 15.73333333,\n",
    "                11.31666667, 21, 18.83333333, 31.6, 20.41666667, 3.783333333, 2.233333333, 12.31666667, 20.58333333,\n",
    "                18.28333333, 13.95]\n",
    "start_depth = [120.95001, 1629.09, 4552, 4964.7676, 5112, 5112.0776, 5505.0513, 5892.058, 6360.5713, 6527.22,\n",
    "               6945.0454, 7389, 8024.0015, 8242.251, 8392.4375, 8535.091, 9064.573, 9747.119, 10490.042]\n",
    "end_depth = [1629.0634, 4556.19, 4964.3687, 5113.364, 5379.8945, 5472.668, 5855.826, 6360.453, 6526.268, 6944.9404,\n",
    "             7394.7295, 8024.3887, 8241.282, 8391.413, 8540.855, 9064.383, 9747.942, 10490.022, 10960.597]\n",
    "run_length = [1508.11339, 2927.1, 412.3687, 148.5964, 267.8945, 360.5904, 350.7747, 468.395, 165.6967, 417.7204,\n",
    "              449.6841, 635.3887, 217.2805, 149.162, 148.4175, 529.292, 683.369, 742.903, 470.555]\n",
    "bit_make = [\"NOV\", \"NOV\", \"Smith\", \"Smith\", \"Smith\", \"Ulterra\", None, \"NOV\", \"NOV\", \"NOV\", \"NOV\", \"NOV\",\n",
    "            \"NOV\", \"NOV\", \"NOV\", \"NOV\", \"NOV\", \"NOV\", \"NOV\"]\n",
    "bit_model = [\"TKC76\", \"TKC66\", \"MDSi616\", \"Z713S\", \"XS616\", \"U616M\", None, \"TKC63\", \"SKC613M\", \"SKC513M\",\n",
    "             \"FTKC63-01\", \"TKC63\", \"SKC513M\", \"SKC613M\", \"SKC613M\", \"TKC63\", \"FTKC63-01\", \"TKC63\", \"TKC63\"]\n",
    "bit_od = [17.5, 12.25, 12.25, 12.25, 12.25, 12.25, None, 8.75, 8.75, 8.75, 8.75, 8.75, 8.75, 8.75, 8.75, 8.75,\n",
    "          8.75, 8.75, 8.75]\n",
    "motor = [False, True, True, True, True, True, None, True, True, True, True, True, True, True, True, True, True, True, True]\n",
    "motor_make = [None, \"Scout\", \"Scout\", \"Scout\", \"Scout\", \"Scout\", None, \"Scout\", \"Scout\", \"Scout\", \"Scout\", \"Scout\",\n",
    "              \"Scout\", \"Scout\", \"Scout\", \"Scout\", \"Scout\", \"Scout\", \"Scout\"]\n",
    "motor_od = [None, 9.625, 9.625, 9.625, 9.625, 9.625, None, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5]\n",
    "motor_config = [None, \"7/8-5.9\", \"7/8-5.9\", \"7/8-5.9\", \"7/8-5.9\", \"7/8-3.0\", None, \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\",\n",
    "                \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\"]\n",
    "rss = [True, True, True, True, True, True, None, False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False]\n",
    "rss_make = [\"Scout Vertical\", \"Scout Vertical\", \"Scout Vertical\", \"Scout Vertical\", \"Scout Vertical\", \"Scout Vertical\",\n",
    "            None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
    "\n",
    "# Create a new DataFrame with the provided data\n",
    "bit_run_dict = {\n",
    "    'run_number': run_number,\n",
    "    'start_time': start_time,\n",
    "    'end_time': end_time,\n",
    "    'run_duration': run_duration,\n",
    "    'start_depth': start_depth,\n",
    "    'end_depth': end_depth,\n",
    "    'run_length': run_length,\n",
    "    'bit_make': bit_make,\n",
    "    'bit_model': bit_model,\n",
    "    'bit_od': bit_od,\n",
    "    'motor': motor,\n",
    "    'motor_make': motor_make,\n",
    "    'motor_od': motor_od,\n",
    "    'motor_config': motor_config,\n",
    "    'rss': rss,\n",
    "    'rss_make': rss_make\n",
    "}\n",
    "bit_run_df = pd.DataFrame(bit_run_dict)\n",
    "bit_run_df['avg_rop'] = bit_run_df['run_length'] / bit_run_df['run_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8b9cd",
   "metadata": {},
   "source": [
    "## 2 🔹 Grouping with `.groupby()`\n",
    "\n",
    "Grouping allows us to split our data into segments based on a column value, then perform calculations on each group independently.\n",
    "\n",
    "### 🔧 Syntax\n",
    "```python\n",
    "df.groupby(\"column_name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df.groupby('bit_make').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa89d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_make_counts = bit_run_df.groupby('bit_make').size().reset_index(name='count')\n",
    "bit_make_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551a8442",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_runs_grouped = bit_run_df.groupby(['bit_od', 'bit_make']).size().reset_index(name='count')\n",
    "bit_runs_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a625e",
   "metadata": {},
   "source": [
    "## 3 📊 Aggregating Multiple Metrics with `.agg()`\n",
    "\n",
    "Aggregation is how we apply multiple statistical functions to grouped data. This is where `.agg()` shines.\n",
    "\n",
    "### 🔧 Syntax\n",
    "```python\n",
    "df.groupby(\"bit_model\").agg({\n",
    "    \"rop\": \"mean\",\n",
    "    \"torque\": \"max\",\n",
    "    \"wob\": \"std\"\n",
    "})\n",
    "```\n",
    "\n",
    "### 📌 Why It Matters\n",
    "You can quickly create summary reports that show how different combinations of equipment perform:\n",
    "- Which bit models produce the highest ROP?\n",
    "- Which motor configurations generate the most torque?\n",
    "- Where is the variability the highest?\n",
    "\n",
    "Hands-on: Use `.agg()` to summarize 2-3 performance metrics for a key grouping (e.g., `run_number`, `bit_make`, or `interval_type`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395b15c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_runs_grouped = bit_run_df.groupby(['bit_od', 'bit_make']).agg(\n",
    "    count=('run_number', 'size'),\n",
    "    avg_run_duration=('run_duration', 'mean'),\n",
    "    avg_run_length=('run_length', 'mean'),\n",
    ").reset_index()\n",
    "bit_runs_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f89df82",
   "metadata": {},
   "source": [
    "**Now you try**\n",
    "\n",
    "Group by bit_od and bit_make. Then calculate avg_rop for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c568704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6249211c",
   "metadata": {},
   "source": [
    "## 4 🔍 Slicing Data with `.loc[]`\n",
    "\n",
    "`.loc[]` allows us to filter rows and select specific columns, all in one go.\n",
    "\n",
    "### 🔧 Syntax\n",
    "```python\n",
    "df.loc[condition, [\"column1\", \"column2\"]]\n",
    "```\n",
    "\n",
    "### 📌 Example\n",
    "Filter out runs with large bits:\n",
    "```python\n",
    "df.loc[df[\"bit_od\"] > 8.5, [\"bit_model\", \"avg_rop\", \"run_duration\", \"run_length\"]]\n",
    "```\n",
    "\n",
    "You can also combine multiple conditions using `&` (and) or `|` (or):\n",
    "```python\n",
    "df.loc[(df[\"motor\"] == True) & (df[\"formation\"] == \"Wolfcamp\")]\n",
    "```\n",
    "\n",
    "Use `.loc[]` when you want precision and control while filtering or subsetting your dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f23a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen = (bit_run_df.bit_od == 8.75)\n",
    "bit_run_df.loc[screen, 'bit_make']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen = (bit_run_df.bit_od == 8.75)\n",
    "bit_run_df.loc[screen, 'bit_make'] = 'National Oilwell Varco'\n",
    "bit_run_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34a18ef",
   "metadata": {},
   "source": [
    "## 4 🧪 Data QA/QC: Catching Dirty Data Before It Catches You\n",
    "\n",
    "Before diving into analysis or modeling, you must understand the quality of your data.\n",
    "\n",
    "### ⚠️ Common Issues\n",
    "- Missing values (NaNs)\n",
    "- Duplicate rows\n",
    "- Out-of-range or impossible values (e.g., RPM > 1000)\n",
    "\n",
    "### 🔧 Tools for QA/QC\n",
    "```python\n",
    "df.isna().sum()             # Count missing values\n",
    "df.duplicated().sum()       # Count duplicates\n",
    "df.describe()               # Quick sanity check on ranges\n",
    "IQR Outlier Removal         # Remove outliers with inter-quartile-range method\n",
    "```\n",
    "\n",
    "### 🧠 Drilling-Specific QC Ideas\n",
    "- Is depth ever negative?\n",
    "- Are there values beyond what’s physically possible?\n",
    "- Does every run have a start and end time?\n",
    "\n",
    "Hands-on: Write a few simple checks to flag suspect rows. For example:\n",
    "```python\n",
    "df[df[\"rpm\"] > 500]\n",
    "```\n",
    "\n",
    "Think of this as debugging your dataset before launching your analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9587ab3d",
   "metadata": {},
   "source": [
    "Import on_btm_df locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf22ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the on_btm_df from a CSV file\n",
    "file_name = 'on_btm_df.csv'\n",
    "# get current directory\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "file_path = os.path.join(current_directory, file_name)\n",
    "print(file_path)\n",
    "on_btm_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a9f6e",
   "metadata": {},
   "source": [
    "from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918284f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "file_name = 'on_btm_df.csv'  # Replace with your file name once uploaded to Google Drive\n",
    "\n",
    "file_path = f'/content/drive/My Drive/python-for-drilling-engineers/module_2/{file_name}'\n",
    "\n",
    "on_btm_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae01db8f",
   "metadata": {},
   "source": [
    "### Missing Data, Duplicate Data, Quick Checks\n",
    "```python\n",
    "df.info()                   # Quick column check and null counts\n",
    "df.isna().sum()             # Count missing values\n",
    "df.duplicated().sum()       # Count duplicates\n",
    "df.describe()               # Quick sanity check on ranges\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_btm_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_btm_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75e6abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_btm_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d3384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_btm_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226c639e",
   "metadata": {},
   "source": [
    "#### Removing Null Values and -999's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d592cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Null Values with 0 in the 'rop' and 'wob' columns\n",
    "columns_to_replace = ['rop', 'wob', 'diff_press', 'td_rpm', 'td_torque']\n",
    "on_btm_df['columns_to_replace'].fillna(0, inplace=True)\n",
    "on_btm_df['wob'].fillna(0, inplace=True)\n",
    "# Verify that the null values have been replaced\n",
    "on_btm_df.info()  # Check the DataFrame info again to ensure no nulls in 'rop' and 'wob'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f957534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace -999 values with None in the 'rop' and 'wob' columns\n",
    "on_btm_df.loc[on_btm_df['rop'] == -999.99, 'rop'] = None\n",
    "on_btm_df.loc[on_btm_df['wob'] == -999.99, 'wob'] = None\n",
    "\n",
    "# Alternative method using replace\n",
    "# on_btm_df['rop'].replace(-999.99, None, inplace=True)\n",
    "# on_btm_df['wob'].replace(-999.99, None, inplace=True)\n",
    "\n",
    "# Verify that the -999 values have been replaced\n",
    "on_btm_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f037d0",
   "metadata": {},
   "source": [
    "###  Remove Outliers with IQR Method\n",
    "\n",
    "First, let's filter down the dataframe to just the runs we want to look at (18, 23, 26) and rotating only data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d16e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_analysis_df = on_btm_df.copy()  # Create a copy of the DataFrame for analysis\n",
    "param_name_list = ['rop', 'wob', 'td_rpm', 'td_torque', 'diff_press']\n",
    "rpm_rotating_thresh = 40  # RPM threshold for rotating\n",
    "torque_rotating_thresh = 5000  # Torque threshold for rotating\n",
    "run_number_list = [18, 23, 26]  # List of run numbers to analyze\n",
    "\n",
    "run_screen = (on_btm_df['run_number'].isin(run_number_list))  # Filter the DataFrame to only include the run numbers in the list\n",
    "rotating_screen = (on_btm_df['td_rpm'] > rpm_rotating_thresh) & (on_btm_df['td_torque'] > torque_rotating_thresh)\n",
    "run_analysis_df = on_btm_df[run_screen & rotating_screen]\n",
    "\n",
    "print(\"\\n\\n Filtered DataFrame before Outlier Removal:\")\n",
    "run_analysis_df.describe()  # Display the statistics of the filtered DataFrame before outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec9d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_per_column(df, column_names):\n",
    "    # Fill NaNs once for all selected columns\n",
    "    df[column_names] = df[column_names].fillna(0)\n",
    "    \n",
    "    for col in column_names:\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Group by run_number and apply the outlier removal\n",
    "all_run_df = (\n",
    "    run_analysis_df[run_analysis_df['run_number'].isin(run_number_list)]\n",
    "    .groupby('run_number', group_keys=False)\n",
    "    .apply(lambda df: remove_outliers_per_column(df.copy(), param_name_list))\n",
    ")\n",
    "\n",
    "print(\"\\n\\n Filtered DataFrame after Outlier Removal:\")\n",
    "all_run_df.describe()  # Display the statistics of the filtered DataFrame after outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33f06fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_run_df.to_csv('all_run_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0c2005",
   "metadata": {},
   "source": [
    "#### Pandas Profiling Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52877046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on GoogleColab, you must pip install ydata-profiling before running the next cell\n",
    "!pip install ydata-profiling\n",
    "\n",
    "# Generate a profile report\n",
    "from ydata_profiling import ProfileReport\n",
    "profile = ProfileReport(on_btm_df, title=\"Forge 16A Data Analysis\", explorative=True)\n",
    "profile.to_notebook_iframe()\n",
    "# Save the profile report to an HTML file\n",
    "profile.to_file(output_file=\"forge_16A_on_btm_report.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
