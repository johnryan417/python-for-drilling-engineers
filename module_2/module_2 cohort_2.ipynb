{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa546ae7",
   "metadata": {},
   "source": [
    "# Python for Drilling Engineers - Module 2\n",
    "## Today's Objectives\n",
    "- Loading Your Own Datasets\n",
    "- DataFrames Walkthrough\n",
    "  - Filtering\n",
    "  - Calculating KPIs\n",
    "  - \n",
    "- Data QA/QC Processes\n",
    "\n",
    "# Module 2: From Excel to Empowered â€“ Working with DataFrames in Python ðŸš€\n",
    "\n",
    "Welcome to Module 2! If you're a drilling engineer who's been living in Excel for years, this is where the journey gets exciting. Python unlocks *next-level control, speed, and insights* from your dataâ€”and it all starts with mastering the DataFrame.\n",
    "\n",
    "In this notebook, youâ€™ll learn how to go from a basic spreadsheet mindset to a confident Python-powered workflow. Step by step. No overwhelm.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ” What We'll Cover\n",
    "\n",
    "This module is intentionally focused and practical. Here's what you'll learn:\n",
    "\n",
    "### 1. Why DataFrames?\n",
    "- What a DataFrame is (and why it's like Excelâ€”but better)\n",
    "- How drilling engineers can benefit: filtering, aggregating, plotting, and automating common workflows\n",
    "- Quick side-by-side: Excel vs. Python for rig data\n",
    "\n",
    "### 2. Setting the Stage: Load Your First Real Dataset\n",
    "- Load the Forge 16A well bit run dataset\n",
    "- Quick overview of the data: rows, columns, and what's inside\n",
    "\n",
    "### 3. Getting Comfortable: Exploring Your Data\n",
    "- `.head()`, `.info()`, `.describe()` â€” fast ways to peek under the hood\n",
    "- How to identify bad or missing data early\n",
    "- Simple column selection and row slicing\n",
    "\n",
    "### 4. Making it Useful: Filtering & Sorting Like a Pro\n",
    "- Filtering rows by bit_od, bit manufacturerer, etc.\n",
    "- Sorting your DataFrames\n",
    "\n",
    "### 5. Adding Value: Creating New Columns & Grouping\n",
    "- Calculating new metrics like \"ROP ft/hr\" or \"Torque-to-WOB ratio\"\n",
    "- Vectorized operations: Why it's *fast* and *clean*\n",
    "\n",
    "### 6. Creating a 'Channel Mapper'\n",
    "- Create a dictionary to define consistent channel names for your dataset\n",
    "- Load and apply it to the Forge 16A Dataset\n",
    "\n",
    "### 7. BONUS: Quick Charting with `matplotlib` and `pandas`\n",
    "- Param Plots\n",
    "- KPI Bar Charts\n",
    "- Why visualizing in Python beats Excel every time\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ‘·â€â™‚ï¸ Why This Matters for You\n",
    "\n",
    "If you're still relying solely on Excel, you're leaving insightâ€”and timeâ€”on the table. This module gives you the tools to:\n",
    "\n",
    "âœ… Make better decisions, faster  \n",
    "âœ… Catch data issues before they catch you  \n",
    "âœ… Automate the boring stuff  \n",
    "âœ… Impress your team with insights they didnâ€™t even know were possible  \n",
    "\n",
    "This is just the beginning. Letâ€™s get after it.\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ§  **Pro Tip:** Bookmark the commands and use them in your daily workflows. The more you use Python, the more it works *for* you.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86b8630",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d70f3df-2bf3-443c-af82-0681a92b1a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the bit_run_df from a CSV file\n",
    "file_name = 'bit_run_df.csv'\n",
    "\n",
    "bit_run_df = pd.read_csv('bit_run_df.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a24cd1",
   "metadata": {},
   "source": [
    "If you have not sent your gmail to connect to Google Drive yet, run this code to create the bit_run_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0ebc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "run_number = [4, 5, 6, 7, 10, 11, 13, 15, 16, 17, 18, 23, 26, 27, 28, 30, 31, 32, 33]\n",
    "start_time = [\"10/30/2020 3:20\", \"11/4/2020 8:49\", \"11/7/2020 16:38\", \"11/9/2020 22:41\", \"11/14/2020 11:43\",\n",
    "              \"11/15/2020 2:46\", \"11/20/2020 0:20\", \"11/24/2020 2:46\", \"11/25/2020 23:21\", \"11/26/2020 22:57\",\n",
    "              \"11/28/2020 14:49\", \"12/3/2020 23:23\", \"12/7/2020 3:30\", \"12/8/2020 20:34\", \"12/9/2020 13:17\",\n",
    "              \"12/12/2020 12:35\", \"12/13/2020 11:44\", \"12/17/2020 0:21\", \"12/18/2020 10:01\"]\n",
    "end_time = [\"10/31/2020 4:27\", \"11/7/2020 6:25\", \"11/8/2020 22:54\", \"11/10/2020 14:58\", \"11/14/2020 16:20\",\n",
    "            \"11/16/2020 13:28\", \"11/22/2020 6:35\", \"11/24/2020 18:30\", \"11/26/2020 10:40\", \"11/27/2020 19:57\",\n",
    "            \"11/29/2020 9:39\", \"12/5/2020 6:59\", \"12/7/2020 23:55\", \"12/9/2020 0:21\", \"12/9/2020 15:31\",\n",
    "            \"12/13/2020 0:54\", \"12/14/2020 8:19\", \"12/17/2020 18:38\", \"12/18/2020 23:58\"]\n",
    "run_duration = [25.11666667, 69.59722222, 30.26666667, 16.28333333, 4.616666667, 34.70277778, 54.25, 15.73333333,\n",
    "                11.31666667, 21, 18.83333333, 31.6, 20.41666667, 3.783333333, 2.233333333, 12.31666667, 20.58333333,\n",
    "                18.28333333, 13.95]\n",
    "start_depth = [120.95001, 1629.09, 4552, 4964.7676, 5112, 5112.0776, 5505.0513, 5892.058, 6360.5713, 6527.22,\n",
    "               6945.0454, 7389, 8024.0015, 8242.251, 8392.4375, 8535.091, 9064.573, 9747.119, 10490.042]\n",
    "end_depth = [1629.0634, 4556.19, 4964.3687, 5113.364, 5379.8945, 5472.668, 5855.826, 6360.453, 6526.268, 6944.9404,\n",
    "             7394.7295, 8024.3887, 8241.282, 8391.413, 8540.855, 9064.383, 9747.942, 10490.022, 10960.597]\n",
    "run_length = [1508.11339, 2927.1, 412.3687, 148.5964, 267.8945, 360.5904, 350.7747, 468.395, 165.6967, 417.7204,\n",
    "              449.6841, 635.3887, 217.2805, 149.162, 148.4175, 529.292, 683.369, 742.903, 470.555]\n",
    "bit_make = [\"NOV\", \"NOV\", \"Smith\", \"Smith\", \"Smith\", \"Ulterra\", None, \"NOV\", \"NOV\", \"NOV\", \"NOV\", \"NOV\",\n",
    "            \"NOV\", \"NOV\", \"NOV\", \"NOV\", \"NOV\", \"NOV\", \"NOV\"]\n",
    "bit_model = [\"TKC76\", \"TKC66\", \"MDSi616\", \"Z713S\", \"XS616\", \"U616M\", None, \"TKC63\", \"SKC613M\", \"SKC513M\",\n",
    "             \"FTKC63-01\", \"TKC63\", \"SKC513M\", \"SKC613M\", \"SKC613M\", \"TKC63\", \"FTKC63-01\", \"TKC63\", \"TKC63\"]\n",
    "bit_od = [17.5, 12.25, 12.25, 12.25, 12.25, 12.25, None, 8.75, 8.75, 8.75, 8.75, 8.75, 8.75, 8.75, 8.75, 8.75,\n",
    "          8.75, 8.75, 8.75]\n",
    "motor = [False, True, True, True, True, True, None, True, True, True, True, True, True, True, True, True, True, True, True]\n",
    "motor_make = [None, \"Scout\", \"Scout\", \"Scout\", \"Scout\", \"Scout\", None, \"Scout\", \"Scout\", \"Scout\", \"Scout\", \"Scout\",\n",
    "              \"Scout\", \"Scout\", \"Scout\", \"Scout\", \"Scout\", \"Scout\", \"Scout\"]\n",
    "motor_od = [None, 9.625, 9.625, 9.625, 9.625, 9.625, None, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5]\n",
    "motor_config = [None, \"7/8-5.9\", \"7/8-5.9\", \"7/8-5.9\", \"7/8-5.9\", \"7/8-3.0\", None, \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\",\n",
    "                \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\"]\n",
    "rss = [True, True, True, True, True, True, None, False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False]\n",
    "rss_make = [\"Scout Vertical\", \"Scout Vertical\", \"Scout Vertical\", \"Scout Vertical\", \"Scout Vertical\", \"Scout Vertical\",\n",
    "            None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
    "\n",
    "# Create a new DataFrame with the provided data\n",
    "bit_run_dict = {\n",
    "    'run_number': run_number,\n",
    "    'start_time': start_time,\n",
    "    'end_time': end_time,\n",
    "    'run_duration': run_duration,\n",
    "    'start_depth': start_depth,\n",
    "    'end_depth': end_depth,\n",
    "    'run_length': run_length,\n",
    "    'bit_make': bit_make,\n",
    "    'bit_model': bit_model,\n",
    "    'bit_od': bit_od,\n",
    "    'motor': motor,\n",
    "    'motor_make': motor_make,\n",
    "    'motor_od': motor_od,\n",
    "    'motor_config': motor_config,\n",
    "    'rss': rss,\n",
    "    'rss_make': rss_make\n",
    "}\n",
    "bit_run_df = pd.DataFrame(bit_run_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35125bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c031ea6a",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa84d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df.head(1)  # Display the first few rows of the DataFrame to verify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15212205",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df.info()  # Display information about the DataFrame, including data types and non-null counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffc5637",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0215def",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df['run_duration'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760901e8",
   "metadata": {},
   "source": [
    "## Filtering & Sorting DataFrames\n",
    "\n",
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0365faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for BHA's with a hole size = 12.25\n",
    "\n",
    "filtered_df = bit_run_df[bit_run_df['bit_od'] == 12.25]\n",
    "# Display the filtered DataFrame\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce82773",
   "metadata": {},
   "outputs": [],
   "source": [
    "hole_size = 12.25  # Change this to the desired hole size\n",
    "filtered_df = bit_run_df[bit_run_df['bit_od'] == hole_size]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd770d2",
   "metadata": {},
   "source": [
    "#### Exercise 1 - **Now you try.**\n",
    "\n",
    "Filter the DataFrame to look at the 8.75\" Bit Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d7986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492e582f",
   "metadata": {},
   "source": [
    "### Applying Multiple Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b605af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hole_size = 12.25\n",
    "screen = (bit_run_df['bit_od'] == hole_size)\n",
    "filtered_df = bit_run_df[screen].reset_index(drop=True)\n",
    "# Display the filtered DataFrame\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a306a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hole_size = 12.25\n",
    "bit_make = 'Ulterra'\n",
    "screen = (bit_run_df['bit_od'] == hole_size) & (bit_run_df['bit_make'] == bit_make)\n",
    "filtered_df = bit_run_df[screen].reset_index(drop=True)\n",
    "# Display the filtered DataFrame\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4c57d5",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "\n",
    "**Now you try.**\n",
    "\n",
    "Filter for BHAs where the hole size is 8.75 and the bit model is TKC63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446b7891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339aa70c",
   "metadata": {},
   "source": [
    "### Sorting Like a Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0229a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df.sort_values(by='run_duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a698da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df.sort_values(by='run_duration', ascending=False, inplace=True)\n",
    "bit_run_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95479c97",
   "metadata": {},
   "source": [
    "#### Exercise 3\n",
    "\n",
    "**Now you try.**\n",
    "\n",
    "Sort the BHA's by run_length from greatest to smallest (ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9871a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490e124",
   "metadata": {},
   "source": [
    "## Adding Value - Calculating Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6549e8",
   "metadata": {},
   "source": [
    "Calculate a column called avg_rop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5062003",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df['avg_rop'] = bit_run_df['run_length'] / bit_run_df['run_duration']\n",
    "bit_run_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873e5d4d",
   "metadata": {},
   "source": [
    "### Calculated Columns for Specific Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb21e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the on_btm_df from a CSV file\n",
    "file_name = 'on_btm_df.csv'\n",
    "# get current directory\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "file_path = 'C:\\\\Users\\\\RDavis\\\\Desktop\\\\Github\\\\python-for-drilling-engineers\\\\module_3'\n",
    "print(file_path)\n",
    "on_btm_df = pd.read_csv(f'{file_path}\\\\{file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e38038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "file_path = '/content/drive/My Drive/python-for-drilling-engineers/module_2/on_btm_df.csv'\n",
    "\n",
    "on_btm_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac22f2",
   "metadata": {},
   "source": [
    "### Using a for loop and filtering, you can calculate KPIs from one dataframe and save to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233e5dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in bit_run_df.iterrows():\n",
    "    start_time = row['start_time']\n",
    "    end_time = row['end_time']\n",
    "    screen = (on_btm_df['rig_time'] >= start_time) & (on_btm_df['rig_time'] <= end_time)\n",
    "    filtered_df = on_btm_df[screen].reset_index(drop=True)\n",
    "    avg_wob = filtered_df.wob.mean()\n",
    "    avg_rpm = filtered_df.td_rpm.mean()\n",
    "    avg_rop_raw = filtered_df.rop.mean()\n",
    "    bit_run_df.loc[bit_run_df.index == index, 'avg_wob'] = avg_wob\n",
    "    bit_run_df.loc[bit_run_df.index == index, 'avg_rpm'] = avg_rpm\n",
    "    bit_run_df.loc[bit_run_df.index == index, 'avg_rop_raw'] = avg_rop_raw\n",
    "bit_run_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad4f4cc",
   "metadata": {},
   "source": [
    "## First Look at Real Drilling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5be530",
   "metadata": {},
   "source": [
    "**Load Data from Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e21074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "file_path = '/content/drive/My Drive/python-for-drilling-engineers/module_1/16A_78-32_time_data_10s_intervals_standard.csv'\n",
    "\n",
    "forge_16A_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02796abb",
   "metadata": {},
   "source": [
    "The first row contains unit information. Let's save it as a dictionary for reference, then remove the row from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ecbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the first row as a dictionary with the key as the column name and the value as the first row value.\n",
    "unit_dict = forge_16A_df.iloc[0].to_dict()\n",
    "print(unit_dict)\n",
    "\n",
    "print(f'ROP units: {unit_dict[\"Rate of Penetration (Depth/Hour)\"]}')  # Access the ROP units\n",
    "print(unit_dict['Rate of Penetration (Minute/Depth)'])\n",
    "\n",
    "# drop first row (units)\n",
    "forge_16A_df.drop(index=0, inplace=True)  # Drop the first row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77eb82c",
   "metadata": {},
   "source": [
    "Now Let's take a look at the data types and non-null counts for each column using the .info function in the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c395860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "forge_16A_df.info()  # Display DataFrame info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14433587",
   "metadata": {},
   "source": [
    "Several columns are null. Let's remove them to focus our efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de6e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with lte 1 non-null value\n",
    "forge_16A_df = forge_16A_df.dropna(axis=1, thresh=2)\n",
    "print(forge_16A_df.info(max_cols=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8216a003",
   "metadata": {},
   "source": [
    "##  Mapping Channels\n",
    "Let's make a copy of our dataframe so as we manipulate the data, the original dataset remains preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f765b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = forge_16A_df.copy()  # Create a copy of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428743dc",
   "metadata": {},
   "source": [
    "Let's clean up the DataFrame a bit:\n",
    "1. Rename our columns to have a more code-friendly title.\n",
    "2. Reduce the columns to only what we care about.\n",
    "3. Set the rig_time column type to datetime.\n",
    "4. Sort the dataframe by 'rig_time'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4890fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original Columns:')\n",
    "print(forge_16A_df.columns)  # Check the columns in the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb0c0eb",
   "metadata": {},
   "source": [
    "### Channel Mapper Creation\n",
    "\n",
    "Use a dictionary to create a channel mapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46556624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the channel mapper dictionary\n",
    "channel_mapper_dict = {\n",
    "    'Date': 'rig_time',\n",
    "    'Bit Diameter': 'bit_size',\n",
    "    'Top Drive Revolutions per Minute': 'td_rpm',\n",
    "    'Bit Revolutions per Minute': 'bit_rpm',\n",
    "    'Weight on Bit': 'wob',\n",
    "    'Differential Pressure': 'diff_press',\n",
    "    'Block Position': 'block_height',\n",
    "    'Rate of Penetration (Depth/Hour)': 'rop',\n",
    "    'Depth Hole Total Vertical Depth': 'md',\n",
    "    'Inclination': 'inc',\n",
    "    'Azimuth': 'azi',\n",
    "    'Hookload': 'hookload',\n",
    "    'Pump Pressure': 'pump_press',\n",
    "    'Return Flow': 'flow_out',\n",
    "    'Flow In': 'flow_in',\n",
    "    'Top Drive Torque': 'td_torque',\n",
    "    'Gamma Measured while Drilling': 'gamma',\n",
    "    'Rig Mode': 'rig_mode',\n",
    "    'On Bottom': 'on_bottom_status',\n",
    "    'Total Strokes per Minute': 'total_spm'\n",
    "}\n",
    "\n",
    "# Rename column headers using the dictionary\n",
    "df.rename(columns=channel_mapper_dict, inplace=True)\n",
    "\n",
    "print('Renamed Columns:')\n",
    "print(df.columns)  # Check the renamed columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173e9f7",
   "metadata": {},
   "source": [
    "### Limit the Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b8a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange and limit the columns in the dataframe\n",
    "df = df[['rig_time', 'md', 'rop', 'wob', 'diff_press', 'td_rpm', 'td_torque',\n",
    "         'bit_rpm', 'block_height', 'inc', 'azi', 'bit_size', 'on_bottom_status']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40419ab9",
   "metadata": {},
   "source": [
    "### Use .describe to get a look under the hood\n",
    "\n",
    "`.describe()` gives you a look at the data distributions in each of your columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae89dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2cc985",
   "metadata": {},
   "source": [
    "**There's a problem with our data types that is keeping `.describe()` from working as expected.**\n",
    "\n",
    "We need to change the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ff8b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set each column as type 'float' except rig_time, which should be a datetime\n",
    "for col in df.columns:\n",
    "    if col != 'rig_time':\n",
    "        df[col] = df[col].astype(float)\n",
    "    if col == 'rig_time':\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe747bc",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "**Create Your Own Mappers for 5 Wells**\n",
    "\n",
    "1. Create a new Jupyter Notebook in Google Colab:\n",
    "   1. Go to https://colab.research.google.com/.\n",
    "   2. Click **+ New notebook**\n",
    "2. Save it to the **python-for-drilling-engineers** Google Drive in the module_2 folder as **last_name_mod_2_hw.ipynb**.\n",
    "3. Download EDR data from 3 of your recent wells, grabbing all the available channels (traces).\n",
    "4. Load them into your Jupyter notebook.\n",
    "5. Use `.info` and `.describe` to understand the data sets for the first well.\n",
    "6. Create a **channel_mapper_dict** to map the channels to standard channel mnemonics.\n",
    "7. Use `.rename()` function to rename the columns to your standard defined in **channel_mapper_dict**.\n",
    "8. Load the next two wells and repeat the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb8dff",
   "metadata": {},
   "source": [
    "# Bonus Learning\n",
    "## Plotting Basics\n",
    "\n",
    "### DVD Plot\n",
    "We're ready to start our analysis.\n",
    "\n",
    "Let's wrap our heads around the dataset by visualizing a common DVD curve using **MatPlotLib**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e172e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MatPlotLib and Seaborn libraries for plotting.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reduce the frequency of the dataframe to make the plot less heavy\n",
    "plot_df = df.copy()\n",
    "plot_df = plot_df.iloc[::240, :]  # Take every 240th row using python slice notation --> start:stop:step\n",
    "# drop rows where rig_time or md is null\n",
    "plot_df.dropna(subset=['rig_time', 'md'], inplace=True)\n",
    "# set rig_time as datetime\n",
    "# plot_df['rig_time'] = pd.to_datetime(plot_df['rig_time'], errors='coerce')  # Convert to datetime\n",
    "plot_df['rig_time'] = plot_df['rig_time'].dt.strftime('%Y-%m-%d %H:%M:%S')  # Format datetime\n",
    "\n",
    "# convert md to numeric\n",
    "plot_df['md'] = pd.to_numeric(plot_df['md'], errors='coerce')\n",
    "\n",
    "print(f'Reduced row count: {plot_df.shape[0]}')  # Check the number of rows after reduction\n",
    "\n",
    "# Ensure plots are displayed in Jupyter Notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# plot line graph x axis = rig_time, y axis = bit_depth, then invert the y-axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(plot_df['rig_time'], plot_df['md'], label='Bit Depth', color='blue')\n",
    "# Reduce the x-axis ticks to only show every 200th tick\n",
    "plt.xticks(plot_df['rig_time'][::200], rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis\n",
    "plt.xlabel('Rig Time')  # Set x-label\n",
    "plt.ylabel('Depth (ft)')  # Set y-label\n",
    "plt.title('DvD Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2223908",
   "metadata": {},
   "source": [
    "## Grouping Your DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df8eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df.groupby('bit_make').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_make_counts = bit_run_df.groupby('bit_make').size().reset_index(name='count')\n",
    "bit_make_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e38d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_runs_grouped = bit_run_df.groupby(['bit_od', 'bit_make']).size().reset_index(name='count')\n",
    "bit_runs_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d3561",
   "metadata": {},
   "source": [
    "### Calculating Statistics on Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608fe427",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_runs_grouped = bit_run_df.groupby(['bit_od', 'bit_make']).agg(\n",
    "    count=('run_number', 'size'),\n",
    "    avg_run_duration=('run_duration', 'mean'),\n",
    "    avg_run_length=('run_length', 'mean'),\n",
    ").reset_index()\n",
    "bit_runs_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd71f222",
   "metadata": {},
   "source": [
    "#### Exercise 4 - **Now You Try**\n",
    "\n",
    "Group the bit runs by bit_od, bit_make, bit model and calculate the run count and the average ROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301bfa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
