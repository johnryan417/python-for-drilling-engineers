{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa546ae7",
   "metadata": {},
   "source": [
    "# Python for Drilling Engineers - Module 2\n",
    "## Today's Objectives\n",
    "- Loading Your Own Datasets\n",
    "- DataFrames Walkthrough\n",
    "  - Filtering\n",
    "  - Calculating KPIs\n",
    "  - \n",
    "- Data QA/QC Processes\n",
    "\n",
    "# Module 2: From Excel to Empowered ‚Äì Working with DataFrames in Python üöÄ\n",
    "\n",
    "Welcome to Module 2! If you're a drilling engineer who's been living in Excel for years, this is where the journey gets exciting. Python unlocks *next-level control, speed, and insights* from your data‚Äîand it all starts with mastering the DataFrame.\n",
    "\n",
    "In this notebook, you‚Äôll learn how to go from a basic spreadsheet mindset to a confident Python-powered workflow. Step by step. No overwhelm.\n",
    "\n",
    "---\n",
    "\n",
    "## üîç What We'll Cover\n",
    "\n",
    "This module is intentionally focused and practical. Here's what you'll learn:\n",
    "\n",
    "### 1. Why DataFrames?\n",
    "- What a DataFrame is (and why it's like Excel‚Äîbut better)\n",
    "- How drilling engineers can benefit: filtering, aggregating, plotting, and automating common workflows\n",
    "- Quick side-by-side: Excel vs. Python for rig data\n",
    "\n",
    "### 2. Setting the Stage: Load Your First Real Dataset\n",
    "- Load the Forge 16A well bit run dataset\n",
    "- Quick overview of the data: rows, columns, and what's inside\n",
    "\n",
    "### 3. Getting Comfortable: Exploring Your Data\n",
    "- `.head()`, `.info()`, `.describe()` ‚Äî fast ways to peek under the hood\n",
    "- How to identify bad or missing data early\n",
    "- Simple column selection and row slicing\n",
    "\n",
    "### 4. Making it Useful: Filtering & Sorting Like a Pro\n",
    "- Filtering rows by bit_od, bit manufacturerer, etc.\n",
    "- Sorting your DataFrames\n",
    "\n",
    "### 5. Adding Value: Creating New Columns & Grouping\n",
    "- Calculating new metrics like \"ROP ft/hr\" or \"Torque-to-WOB ratio\"\n",
    "- Vectorized operations: Why it's *fast* and *clean*\n",
    "\n",
    "### 6. Creating a 'Channel Mapper'\n",
    "- Create a dictionary to define consistent channel names for your dataset\n",
    "- Load and apply it to the Forge 16A Dataset\n",
    "\n",
    "### 7. BONUS: Quick Charting with `matplotlib` and `pandas`\n",
    "- Param Plots\n",
    "- KPI Bar Charts\n",
    "- Why visualizing in Python beats Excel every time\n",
    "\n",
    "---\n",
    "\n",
    "## üë∑‚Äç‚ôÇÔ∏è Why This Matters for You\n",
    "\n",
    "If you're still relying solely on Excel, you're leaving insight‚Äîand time‚Äîon the table. This module gives you the tools to:\n",
    "\n",
    "‚úÖ Make better decisions, faster  \n",
    "‚úÖ Catch data issues before they catch you  \n",
    "‚úÖ Automate the boring stuff  \n",
    "‚úÖ Impress your team with insights they didn‚Äôt even know were possible  \n",
    "\n",
    "This is just the beginning. Let‚Äôs get after it.\n",
    "\n",
    "---\n",
    "\n",
    "üß† **Pro Tip:** Bookmark the commands and use them in your daily workflows. The more you use Python, the more it works *for* you.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86b8630",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d70f3df-2bf3-443c-af82-0681a92b1a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the bit_run_df from a CSV file\n",
    "file_name = 'bit_run_df.csv'\n",
    "\n",
    "bit_run_df = pd.read_csv('bit_run_df.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a24cd1",
   "metadata": {},
   "source": [
    "If you have not sent your gmail to connect to Google Drive yet, run this code to create the bit_run_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0ebc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "run_number = [4, 5, 6, 7, 10, 11, 13, 15, 16, 17, 18, 23, 26, 27, 28, 30, 31, 32, 33]\n",
    "start_time = [\"10/30/2020 3:20\", \"11/4/2020 8:49\", \"11/7/2020 16:38\", \"11/9/2020 22:41\", \"11/14/2020 11:43\",\n",
    "              \"11/15/2020 2:46\", \"11/20/2020 0:20\", \"11/24/2020 2:46\", \"11/25/2020 23:21\", \"11/26/2020 22:57\",\n",
    "              \"11/28/2020 14:49\", \"12/3/2020 23:23\", \"12/7/2020 3:30\", \"12/8/2020 20:34\", \"12/9/2020 13:17\",\n",
    "              \"12/12/2020 12:35\", \"12/13/2020 11:44\", \"12/17/2020 0:21\", \"12/18/2020 10:01\"]\n",
    "end_time = [\"10/31/2020 4:27\", \"11/7/2020 6:25\", \"11/8/2020 22:54\", \"11/10/2020 14:58\", \"11/14/2020 16:20\",\n",
    "            \"11/16/2020 13:28\", \"11/22/2020 6:35\", \"11/24/2020 18:30\", \"11/26/2020 10:40\", \"11/27/2020 19:57\",\n",
    "            \"11/29/2020 9:39\", \"12/5/2020 6:59\", \"12/7/2020 23:55\", \"12/9/2020 0:21\", \"12/9/2020 15:31\",\n",
    "            \"12/13/2020 0:54\", \"12/14/2020 8:19\", \"12/17/2020 18:38\", \"12/18/2020 23:58\"]\n",
    "run_duration = [25.11666667, 69.59722222, 30.26666667, 16.28333333, 4.616666667, 34.70277778, 54.25, 15.73333333,\n",
    "                11.31666667, 21, 18.83333333, 31.6, 20.41666667, 3.783333333, 2.233333333, 12.31666667, 20.58333333,\n",
    "                18.28333333, 13.95]\n",
    "start_depth = [120.95001, 1629.09, 4552, 4964.7676, 5112, 5112.0776, 5505.0513, 5892.058, 6360.5713, 6527.22,\n",
    "               6945.0454, 7389, 8024.0015, 8242.251, 8392.4375, 8535.091, 9064.573, 9747.119, 10490.042]\n",
    "end_depth = [1629.0634, 4556.19, 4964.3687, 5113.364, 5379.8945, 5472.668, 5855.826, 6360.453, 6526.268, 6944.9404,\n",
    "             7394.7295, 8024.3887, 8241.282, 8391.413, 8540.855, 9064.383, 9747.942, 10490.022, 10960.597]\n",
    "run_length = [1508.11339, 2927.1, 412.3687, 148.5964, 267.8945, 360.5904, 350.7747, 468.395, 165.6967, 417.7204,\n",
    "              449.6841, 635.3887, 217.2805, 149.162, 148.4175, 529.292, 683.369, 742.903, 470.555]\n",
    "bit_make = [\"NOV\", \"NOV\", \"Smith\", \"Smith\", \"Smith\", \"Ulterra\", None, \"NOV\", \"NOV\", \"NOV\", \"NOV\", \"NOV\",\n",
    "            \"NOV\", \"NOV\", \"NOV\", \"NOV\", \"NOV\", \"NOV\", \"NOV\"]\n",
    "bit_model = [\"TKC76\", \"TKC66\", \"MDSi616\", \"Z713S\", \"XS616\", \"U616M\", None, \"TKC63\", \"SKC613M\", \"SKC513M\",\n",
    "             \"FTKC63-01\", \"TKC63\", \"SKC513M\", \"SKC613M\", \"SKC613M\", \"TKC63\", \"FTKC63-01\", \"TKC63\", \"TKC63\"]\n",
    "bit_od = [17.5, 12.25, 12.25, 12.25, 12.25, 12.25, None, 8.75, 8.75, 8.75, 8.75, 8.75, 8.75, 8.75, 8.75, 8.75,\n",
    "          8.75, 8.75, 8.75]\n",
    "motor = [False, True, True, True, True, True, None, True, True, True, True, True, True, True, True, True, True, True, True]\n",
    "motor_make = [None, \"Scout\", \"Scout\", \"Scout\", \"Scout\", \"Scout\", None, \"Scout\", \"Scout\", \"Scout\", \"Scout\", \"Scout\",\n",
    "              \"Scout\", \"Scout\", \"Scout\", \"Scout\", \"Scout\", \"Scout\", \"Scout\"]\n",
    "motor_od = [None, 9.625, 9.625, 9.625, 9.625, 9.625, None, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5]\n",
    "motor_config = [None, \"7/8-5.9\", \"7/8-5.9\", \"7/8-5.9\", \"7/8-5.9\", \"7/8-3.0\", None, \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\",\n",
    "                \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\", \"7/8-5.7\"]\n",
    "rss = [True, True, True, True, True, True, None, False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False]\n",
    "rss_make = [\"Scout Vertical\", \"Scout Vertical\", \"Scout Vertical\", \"Scout Vertical\", \"Scout Vertical\", \"Scout Vertical\",\n",
    "            None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
    "\n",
    "# Create a new DataFrame with the provided data\n",
    "bit_run_dict = {\n",
    "    'run_number': run_number,\n",
    "    'start_time': start_time,\n",
    "    'end_time': end_time,\n",
    "    'run_duration': run_duration,\n",
    "    'start_depth': start_depth,\n",
    "    'end_depth': end_depth,\n",
    "    'run_length': run_length,\n",
    "    'bit_make': bit_make,\n",
    "    'bit_model': bit_model,\n",
    "    'bit_od': bit_od,\n",
    "    'motor': motor,\n",
    "    'motor_make': motor_make,\n",
    "    'motor_od': motor_od,\n",
    "    'motor_config': motor_config,\n",
    "    'rss': rss,\n",
    "    'rss_make': rss_make\n",
    "}\n",
    "bit_run_df = pd.DataFrame(bit_run_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35125bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c031ea6a",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa84d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df.head(1)  # Display the first few rows of the DataFrame to verify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15212205",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df.info()  # Display information about the DataFrame, including data types and non-null counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffc5637",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0215def",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df['run_duration'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760901e8",
   "metadata": {},
   "source": [
    "## Filtering & Sorting DataFrames\n",
    "\n",
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0365faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for BHA's with a hole size = 12.25\n",
    "\n",
    "filtered_df = bit_run_df[bit_run_df['bit_od'] == 12.25]\n",
    "# Display the filtered DataFrame\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce82773",
   "metadata": {},
   "outputs": [],
   "source": [
    "hole_size = 12.25  # Change this to the desired hole size\n",
    "filtered_df = bit_run_df[bit_run_df['bit_od'] == hole_size]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd770d2",
   "metadata": {},
   "source": [
    "#### Exercise 1 - **Now you try.**\n",
    "\n",
    "Filter the DataFrame to look at the 8.75\" Bit Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d7986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492e582f",
   "metadata": {},
   "source": [
    "### Applying Multiple Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b605af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hole_size = 12.25\n",
    "screen = (bit_run_df['bit_od'] == hole_size)\n",
    "filtered_df = bit_run_df[screen].reset_index(drop=True)\n",
    "# Display the filtered DataFrame\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a306a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hole_size = 12.25\n",
    "bit_make = 'Ulterra'\n",
    "screen = (bit_run_df['bit_od'] == hole_size) & (bit_run_df['bit_make'] == bit_make)\n",
    "filtered_df = bit_run_df[screen].reset_index(drop=True)\n",
    "# Display the filtered DataFrame\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4c57d5",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "\n",
    "**Now you try.**\n",
    "\n",
    "Filter for BHAs where the hole size is 8.75 and the bit model is TKC63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446b7891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339aa70c",
   "metadata": {},
   "source": [
    "### Sorting Like a Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0229a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df.sort_values(by='run_duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a698da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df.sort_values(by='run_duration', ascending=False, inplace=True)\n",
    "bit_run_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95479c97",
   "metadata": {},
   "source": [
    "#### Exercise 3\n",
    "\n",
    "**Now you try.**\n",
    "\n",
    "Sort the BHA's by run_length from greatest to smallest (ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9871a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490e124",
   "metadata": {},
   "source": [
    "## Adding Value - Calculating Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6549e8",
   "metadata": {},
   "source": [
    "Calculate a column called avg_rop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5062003",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df['avg_rop'] = bit_run_df['run_length'] / bit_run_df['run_duration']\n",
    "bit_run_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873e5d4d",
   "metadata": {},
   "source": [
    "### Calculated Columns for Specific Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb21e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the on_btm_df from a CSV file\n",
    "file_name = 'on_btm_df.csv'\n",
    "# get current directory\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "file_path = 'C:\\\\Users\\\\RDavis\\\\Desktop\\\\Github\\\\python-for-drilling-engineers\\\\module_3'\n",
    "print(file_path)\n",
    "on_btm_df = pd.read_csv(f'{file_path}\\\\{file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e38038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "file_path = '/content/drive/My Drive/python-for-drilling-engineers/module_2/on_btm_df.csv'\n",
    "\n",
    "on_btm_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac22f2",
   "metadata": {},
   "source": [
    "### Using a for loop and filtering, you can calculate KPIs from one dataframe and save to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233e5dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in bit_run_df.iterrows():\n",
    "    start_time = row['start_time']\n",
    "    end_time = row['end_time']\n",
    "    screen = (on_btm_df['rig_time'] >= start_time) & (on_btm_df['rig_time'] <= end_time)\n",
    "    filtered_df = on_btm_df[screen].reset_index(drop=True)\n",
    "    avg_wob = filtered_df.wob.mean()\n",
    "    avg_rpm = filtered_df.td_rpm.mean()\n",
    "    avg_rop_raw = filtered_df.rop.mean()\n",
    "    bit_run_df.loc[bit_run_df.index == index, 'avg_wob'] = avg_wob\n",
    "    bit_run_df.loc[bit_run_df.index == index, 'avg_rpm'] = avg_rpm\n",
    "    bit_run_df.loc[bit_run_df.index == index, 'avg_rop_raw'] = avg_rop_raw\n",
    "bit_run_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad4f4cc",
   "metadata": {},
   "source": [
    "## First Look at Real Drilling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5be530",
   "metadata": {},
   "source": [
    "**Load Data from Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e21074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "file_path = '/content/drive/My Drive/python-for-drilling-engineers/module_1/16A_78-32_time_data_10s_intervals_standard.csv'\n",
    "\n",
    "forge_16A_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02796abb",
   "metadata": {},
   "source": [
    "The first row contains unit information. Let's save it as a dictionary for reference, then remove the row from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ecbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the first row as a dictionary with the key as the column name and the value as the first row value.\n",
    "unit_dict = forge_16A_df.iloc[0].to_dict()\n",
    "print(unit_dict)\n",
    "\n",
    "print(f'ROP units: {unit_dict[\"Rate of Penetration (Depth/Hour)\"]}')  # Access the ROP units\n",
    "print(unit_dict['Rate of Penetration (Minute/Depth)'])\n",
    "\n",
    "# drop first row (units)\n",
    "forge_16A_df.drop(index=0, inplace=True)  # Drop the first row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77eb82c",
   "metadata": {},
   "source": [
    "Now Let's take a look at the data types and non-null counts for each column using the .info function in the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c395860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "forge_16A_df.info()  # Display DataFrame info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14433587",
   "metadata": {},
   "source": [
    "Several columns are null. Let's remove them to focus our efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de6e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with lte 1 non-null value\n",
    "forge_16A_df = forge_16A_df.dropna(axis=1, thresh=2)\n",
    "print(forge_16A_df.info(max_cols=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8216a003",
   "metadata": {},
   "source": [
    "##  Mapping Channels\n",
    "Let's make a copy of our dataframe so as we manipulate the data, the original dataset remains preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f765b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = forge_16A_df.copy()  # Create a copy of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428743dc",
   "metadata": {},
   "source": [
    "Let's clean up the DataFrame a bit:\n",
    "1. Rename our columns to have a more code-friendly title.\n",
    "2. Reduce the columns to only what we care about.\n",
    "3. Set the rig_time column type to datetime.\n",
    "4. Sort the dataframe by 'rig_time'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4890fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original Columns:')\n",
    "print(forge_16A_df.columns)  # Check the columns in the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb0c0eb",
   "metadata": {},
   "source": [
    "### Channel Mapper Creation\n",
    "\n",
    "Use a dictionary to create a channel mapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46556624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the channel mapper dictionary\n",
    "channel_mapper_dict = {\n",
    "    'Date': 'rig_time',\n",
    "    'Bit Diameter': 'bit_size',\n",
    "    'Top Drive Revolutions per Minute': 'td_rpm',\n",
    "    'Bit Revolutions per Minute': 'bit_rpm',\n",
    "    'Weight on Bit': 'wob',\n",
    "    'Differential Pressure': 'diff_press',\n",
    "    'Block Position': 'block_height',\n",
    "    'Rate of Penetration (Depth/Hour)': 'rop',\n",
    "    'Depth Hole Total Vertical Depth': 'md',\n",
    "    'Inclination': 'inc',\n",
    "    'Azimuth': 'azi',\n",
    "    'Hookload': 'hookload',\n",
    "    'Pump Pressure': 'pump_press',\n",
    "    'Return Flow': 'flow_out',\n",
    "    'Flow In': 'flow_in',\n",
    "    'Top Drive Torque': 'td_torque',\n",
    "    'Gamma Measured while Drilling': 'gamma',\n",
    "    'Rig Mode': 'rig_mode',\n",
    "    'On Bottom': 'on_bottom_status',\n",
    "    'Total Strokes per Minute': 'total_spm'\n",
    "}\n",
    "\n",
    "# Rename column headers using the dictionary\n",
    "df.rename(columns=channel_mapper_dict, inplace=True)\n",
    "\n",
    "print('Renamed Columns:')\n",
    "print(df.columns)  # Check the renamed columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173e9f7",
   "metadata": {},
   "source": [
    "### Limit the Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b8a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange and limit the columns in the dataframe\n",
    "df = df[['rig_time', 'md', 'rop', 'wob', 'diff_press', 'td_rpm', 'td_torque',\n",
    "         'bit_rpm', 'block_height', 'inc', 'azi', 'bit_size', 'on_bottom_status']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40419ab9",
   "metadata": {},
   "source": [
    "### Use .describe to get a look under the hood\n",
    "\n",
    "`.describe()` gives you a look at the data distributions in each of your columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae89dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2cc985",
   "metadata": {},
   "source": [
    "**There's a problem with our data types that is keeping `.describe()` from working as expected.**\n",
    "\n",
    "We need to change the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ff8b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set each column as type 'float' except rig_time, which should be a datetime\n",
    "for col in df.columns:\n",
    "    if col != 'rig_time':\n",
    "        df[col] = df[col].astype(float)\n",
    "    if col == 'rig_time':\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe747bc",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "**Create Your Own Mappers for 5 Wells**\n",
    "\n",
    "1. Create a new Jupyter Notebook in Google Colab:\n",
    "   1. Go to https://colab.research.google.com/.\n",
    "   2. Click **+ New notebook**\n",
    "2. Save it to the **python-for-drilling-engineers** Google Drive in the module_2 folder as **last_name_mod_2_hw.ipynb**.\n",
    "3. Download EDR data from 3 of your recent wells, grabbing all the available channels (traces).\n",
    "4. Load them into your Jupyter notebook.\n",
    "5. Use `.info` and `.describe` to understand the data sets for the first well.\n",
    "6. Create a **channel_mapper_dict** to map the channels to standard channel mnemonics.\n",
    "7. Use `.rename()` function to rename the columns to your standard defined in **channel_mapper_dict**.\n",
    "8. Load the next two wells and repeat the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb8dff",
   "metadata": {},
   "source": [
    "# Bonus Learning\n",
    "## Plotting Basics\n",
    "\n",
    "### DVD Plot\n",
    "We're ready to start our analysis.\n",
    "\n",
    "Let's wrap our heads around the dataset by visualizing a common DVD curve using **MatPlotLib**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e172e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MatPlotLib and Seaborn libraries for plotting.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reduce the frequency of the dataframe to make the plot less heavy\n",
    "plot_df = df.copy()\n",
    "plot_df = plot_df.iloc[::240, :]  # Take every 240th row using python slice notation --> start:stop:step\n",
    "# drop rows where rig_time or md is null\n",
    "plot_df.dropna(subset=['rig_time', 'md'], inplace=True)\n",
    "# set rig_time as datetime\n",
    "# plot_df['rig_time'] = pd.to_datetime(plot_df['rig_time'], errors='coerce')  # Convert to datetime\n",
    "plot_df['rig_time'] = plot_df['rig_time'].dt.strftime('%Y-%m-%d %H:%M:%S')  # Format datetime\n",
    "\n",
    "# convert md to numeric\n",
    "plot_df['md'] = pd.to_numeric(plot_df['md'], errors='coerce')\n",
    "\n",
    "print(f'Reduced row count: {plot_df.shape[0]}')  # Check the number of rows after reduction\n",
    "\n",
    "# Ensure plots are displayed in Jupyter Notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# plot line graph x axis = rig_time, y axis = bit_depth, then invert the y-axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(plot_df['rig_time'], plot_df['md'], label='Bit Depth', color='blue')\n",
    "# Reduce the x-axis ticks to only show every 200th tick\n",
    "plt.xticks(plot_df['rig_time'][::200], rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis\n",
    "plt.xlabel('Rig Time')  # Set x-label\n",
    "plt.ylabel('Depth (ft)')  # Set y-label\n",
    "plt.title('DvD Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2223908",
   "metadata": {},
   "source": [
    "## Grouping Your DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df8eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_run_df.groupby('bit_make').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_make_counts = bit_run_df.groupby('bit_make').size().reset_index(name='count')\n",
    "bit_make_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e38d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_runs_grouped = bit_run_df.groupby(['bit_od', 'bit_make']).size().reset_index(name='count')\n",
    "bit_runs_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1d3561",
   "metadata": {},
   "source": [
    "### Calculating Statistics on Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608fe427",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_runs_grouped = bit_run_df.groupby(['bit_od', 'bit_make']).agg(\n",
    "    count=('run_number', 'size'),\n",
    "    avg_run_duration=('run_duration', 'mean'),\n",
    "    avg_run_length=('run_length', 'mean'),\n",
    ").reset_index()\n",
    "bit_runs_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd71f222",
   "metadata": {},
   "source": [
    "#### Exercise 4 - **Now You Try**\n",
    "\n",
    "Group the bit runs by bit_od, bit_make, bit model and calculate the run count and the average ROP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301bfa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your code here.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
