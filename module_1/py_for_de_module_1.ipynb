{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22a57a00",
   "metadata": {},
   "source": [
    "# Python for Drilling Engineers - Module 1\n",
    "## Introduction\n",
    "Welcome to the Python for Drilling Engineers course! In this module, we'll cover the basics of Python and data manipulation for drilling-related applications.\n",
    "\n",
    "**Why Python?**\n",
    "- Open-source and widely used in data science\n",
    "- Great for automating repetitive tasks\n",
    "- Strong ecosystem for data analysis and visualization\n",
    "\n",
    "**What's in it for a drilling engineer?**\n",
    "- Automate drilling KPIs, reports, and calculations\n",
    "- Analyze well logs and real-time drilling data\n",
    "- Unlimited flexibility\n",
    "- Improve decision-making with data-driven insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb4860",
   "metadata": {},
   "source": [
    "## Python Basics: Built-in Data Structures\n",
    "Before working with datasets, let's cover fundamental Python data structures.\n",
    "\n",
    "### Summary Table: Python Data Structures\n",
    "\n",
    "| Data Structure | Ordered? | Mutable? | Duplicates Allowed? | Best Use Case |\n",
    "|---------------|---------|----------|------------------|--------------|\n",
    "| **List** (`list`) | ✅ Yes | ✅ Yes | ✅ Yes | General-purpose, ordered data storage |\n",
    "| **Dictionary** (`dict`) | ❌ No (Python 3.7+ maintains insertion order) | ✅ Yes | ❌ No (keys must be unique) | Key-value lookups, structured data |\n",
    "| **Tuple** (`tuple`) | ✅ Yes | ❌ No | ✅ Yes | Immutable, fixed collections |\n",
    "| **Set** (`set`) | ❌ No | ✅ Yes (elements can be added/removed) | ❌ No | Unique element storage, set operations |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437ef9ff",
   "metadata": {},
   "source": [
    "### Lists\n",
    "**Definition:**\n",
    "A list is an ordered, mutable (modifiable) collection that allows duplicate elements.\n",
    "\n",
    "**Key Features:**\n",
    "- Ordered: elements maintain the order in which they were added\n",
    "- Mutable: Elements can be changed, added, or removed.\n",
    "- Allows Duplicates: Multiple elements with the same value are allowed.\n",
    "\n",
    "**When to Use?**\n",
    "- When you need an ordered collection of items.\n",
    "- When frequent updates (insertion/deletion/modification) are needed.\n",
    "- When you want to store heterogeneous data (e.g., [\"Drill Bit\", 10, 45.7])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca3785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists\n",
    "drilling_tools = ['Bit', 'Mud Motor', 'MWD', 'Rotary Table']\n",
    "print(drilling_tools[0])  # Access first item\n",
    "print(len(drilling_tools))  # Number of elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86addc0c",
   "metadata": {},
   "source": [
    "### Dictionaries\n",
    "**Definition:** A dictionary is an unordered collection of key-value pairs, where keys are unique and immutable.\n",
    "\n",
    "**Key Features:**\n",
    "- Key-value pairs: Allows efficient lookups.\n",
    "- Keys must be unique: No duplicate keys are allowed.\n",
    "- Mutable: You can update values or add new key-value pairs.\n",
    "\n",
    "**When to Use?**\n",
    "- When you need fast lookups based on unique keys.\n",
    "- When you need to store related attributes (e.g., drilling parameters per well).\n",
    "- When you need flexible and structured data storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccbba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries\n",
    "drilling_data = {\n",
    "    'Depth': 5000,\n",
    "    'ROP': 50,\n",
    "    'Mud Weight': 10.5\n",
    "}\n",
    "print(drilling_data['Depth'])  # Accessing dictionary value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412e21ec",
   "metadata": {},
   "source": [
    "### Tuples\n",
    "**Definition:** A tuple is an ordered, immutable collection that allows duplicate elements.\n",
    "\n",
    "**Key Features:**\n",
    "- Ordered: Elements maintain their order.\n",
    "- Immutable: Cannot be changed after creation.\n",
    "- Allows Duplicates: Multiple identical elements are allowed.\n",
    "\n",
    "**When to Use?**\n",
    "- When you need a fixed collection that should not change.\n",
    "- When performance is critical (tuples are faster than lists).\n",
    "- When using as dictionary keys (since they are immutable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf969aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuples\n",
    "drilling_parameters = (5000, 50, 10.5)  # Immutable list\n",
    "print(drilling_parameters[0])  # Access first item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d8d262",
   "metadata": {},
   "source": [
    "### Sets\n",
    "**Definition:** A set is an unordered, mutable collection that only stores unique elements.\n",
    "\n",
    "**Key Features:**\n",
    "- Unordered: No guaranteed element order.\n",
    "- Mutable (but only for adding/removing elements).\n",
    "- No Duplicates: Automatically removes duplicates.\n",
    "\n",
    "**When to Use?**\n",
    "- When you need to store unique values only (e.g., unique well names).\n",
    "- When you need fast membership testing (in operator is fast).\n",
    "- When performing set operations (union, intersection, difference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af089d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets\n",
    "drilling_tools = {'Bit', 'Mud Motor', 'MWD', 'Rotary Table'}\n",
    "print(drilling_tools)  # Unique elements\n",
    "# Step 1: Adding an element to a set\n",
    "drilling_tools.add('Casing')\n",
    "print('Step 1 Result:')\n",
    "print(drilling_tools)\n",
    "# Step 2: Removing an element from a set\n",
    "drilling_tools.remove('Bit')\n",
    "print('Step 2 Result:')\n",
    "print(drilling_tools)\n",
    "# Step 3: Check if an element exists in a set\n",
    "print('Step 3 Result:')\n",
    "print('Bit' in drilling_tools)  # Returns False\n",
    "# Iterating through a set\n",
    "for tool in drilling_tools:\n",
    "    print(tool)\n",
    "\n",
    "# List Comprehensions\n",
    "# Create a list of drilling tools with 'Drill' prefix\n",
    "drilling_tools = ['Bit', 'Mud Motor', 'MWD', 'Rotary Table']\n",
    "drilling_tools_with_prefix = [f'Drill {tool}' for tool in drilling_tools]\n",
    "print(drilling_tools_with_prefix)  # ['Drill Bit', 'Drill Mud Motor', 'Drill MWD', 'Drill Rotary Table']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4405aa",
   "metadata": {},
   "source": [
    "### Dictionary Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4a5f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary Comprehensions\n",
    "# Create a dictionary with drilling tools and their depths\n",
    "drilling_tools = ['Bit', 'Mud Motor', 'MWD', 'stabilizer']\n",
    "tool_od_list = [12.25, 8.5, 8.5, 11.75]  # Outer diameter list\n",
    "# tool_length_list = [1.75, 26.3, 28.5, 7.45]  # Length list\n",
    "# Create a dictionary with drilling tools and their ODs\n",
    "drilling_tool_dict = {tool: od for tool, od in zip(drilling_tools, tool_od_list)}\n",
    "print(drilling_tool_dict)  # {'Bit': 12.25, 'Mud Motor': 8.5, 'MWD': 8.5, 'stabilizer': 11.75}\n",
    "\n",
    "# Get the OD of the MWD from the dictionary:\n",
    "mwd_od = drilling_tool_dict.get('MWD')\n",
    "print(mwd_od)  # 8.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60452737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F-strings & for loops:\n",
    "tool_type = 'Bit'\n",
    "print(f'The {tool_type} has an outer diameter of {drilling_tool_dict[tool_type]} inches.')\n",
    "\n",
    "# Iterate through the dictionary and print each tool's name and outer diameter\n",
    "for name, value in drilling_tool_dict.items():\n",
    "    print(f'The {name} has an outer diameter of {value} inches.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f988515",
   "metadata": {},
   "source": [
    "## Working with DataFrames\n",
    "We'll use Pandas to create and manipulate dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e11c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a simple DataFrame\n",
    "data = {'Depth': [1050, 1100, 1150, 1200], 'ROP': [323, 350, 355, 385], 'WOB': [42, 43, 48, 50], 'RPM': [120, 120, 120, 120], \n",
    "        'DIFF': [458, 473, 491, 526]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f80546e",
   "metadata": {},
   "source": [
    "## Uploading **.csv** Data Files Locally\n",
    "We'll demonstrate how to upload CSV, Excel, and LAS files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f22a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get my current path:\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "# This is the directory where the script is running\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# replace \\ with \\\\ in current_path\n",
    "current_path = current_path.replace('\\\\', '\\\\\\\\')\n",
    "print(f'Current path: {current_path}')  # Print the current path\n",
    "\n",
    "# upload file from current_path\n",
    "file_path = current_path + '\\\\\\\\16A_78-32_time_data_10s_intervals_standard.csv'\n",
    "print(f'File path: {file_path}')\n",
    "\n",
    "forge_16A_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffec9d2",
   "metadata": {},
   "source": [
    "## Uploading **.csv** Data Files from Google Drive\n",
    "\n",
    "The below snippet of code should be run to import the Forge data while running on GoogleColab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312f0f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "file_path = '/content/drive/My Drive/python-for-drilling-engineers/module_1/16A_78-32_time_data_10s_intervals_standard.csv'\n",
    "\n",
    "forge_16A_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf064e",
   "metadata": {},
   "source": [
    "## Rapid Dataset Reviews\n",
    "Let's start by taking a look at the format of the data pulled in from the CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f8774",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forge_16A_df.shape)  # Display the shape of the DataFrame\n",
    "print(f'Row Count: {forge_16A_df.shape[0]} \\nColumn Count: {forge_16A_df.shape[1]}')  # Display row and column count\n",
    "print(f'Column names: \\n {list(forge_16A_df.columns)}')  # Display the column names\n",
    "# print the first 10 rows of the first 5 columns\n",
    "print(f'First look at the dataframe: \\n {forge_16A_df.iloc[:10, :6]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a68d92",
   "metadata": {},
   "source": [
    "The first row contains unit information. Let's save it as a dictionary for reference, then remove the row from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff664cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the first row as a dictionary with the key as the column name and the value as the first row value.\n",
    "first_row_dict = forge_16A_df.iloc[0].to_dict()\n",
    "print(first_row_dict)\n",
    "\n",
    "print(f'ROP units: {first_row_dict['Rate of Penetration (Depth/Hour)']}')  # Access the ROP units\n",
    "print(first_row_dict['Rate of Penetration (Minute/Depth)'])\n",
    "\n",
    "# drop first row (units)\n",
    "forge_16A_df.drop(index=0, inplace=True)  # Drop the first row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee8a9f4",
   "metadata": {},
   "source": [
    "Now Let's take a look at the data types and non-null counts for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b927fef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forge_16A_df.info(max_cols=None))  # Display DataFrame info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4da8be",
   "metadata": {},
   "source": [
    "Several columns are null. Let's remove them to focus our efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96ccab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with lte 1 non-null value\n",
    "forge_16A_df = forge_16A_df.dropna(axis=1, thresh=2)\n",
    "print(forge_16A_df.info(max_cols=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd8d46d",
   "metadata": {},
   "source": [
    "## Run Pandas Profiling Report to Explore the Data Further\n",
    "First, let's define the data type in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925839b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the columns with 'Date' in the header to datetime\n",
    "for col in forge_16A_df.columns:\n",
    "    if 'Date' in col:\n",
    "        forge_16A_df[col] = pd.to_datetime(forge_16A_df[col], errors='coerce')\n",
    "\n",
    "# Set all other columns to float\n",
    "for col in forge_16A_df.columns:\n",
    "    if 'Date' not in col:\n",
    "        forge_16A_df[col] = pd.to_numeric(forge_16A_df[col], errors='coerce')\n",
    "\n",
    "print(forge_16A_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9291615f",
   "metadata": {},
   "source": [
    "Now, let's generate a profile report using the ydata-profiling library (formerly pandas profiling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on GoogleColab, you must pip install ydata-profiling before running the next cell\n",
    "!pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b61ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a profile report\n",
    "from ydata_profiling import ProfileReport\n",
    "profile = ProfileReport(forge_16A_df, title=\"Forge 16A Data Analysis\", explorative=True)\n",
    "profile.to_notebook_iframe()\n",
    "# Save the profile report to an HTML file\n",
    "profile.to_file(output_file=\"forge_16A_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c71278d",
   "metadata": {},
   "source": [
    "Let's rename our columns to have a more code-friendly title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forge_16A_df.columns)  # Check the columns in the DataFrame\n",
    "print(f'Row count: {forge_16A_df.shape[0]}')  # Check the number of rows\n",
    "\n",
    "df = forge_16A_df.copy()\n",
    "# Rename column headers\n",
    "df.rename(columns={'Date': 'rig_time',\n",
    "                   'Bit Diameter': 'bit_size',\n",
    "                   'Top Drive Revolutions per Minute': 'td_rpm',\n",
    "                   'Bit Revolutions per Minute': 'bit_rpm',\n",
    "                   'Weight on Bit': 'wob',\n",
    "                   'Differential Pressure': 'diff_press',\n",
    "                   'Block Position': 'block_height',\n",
    "                   'Rate of Penetration (Depth/Hour)': 'rop',\n",
    "                   'Depth Hole Total Vertical Depth': 'md',\n",
    "                   'Inclination': 'inc',\n",
    "                   'Azimuth': 'azi',\n",
    "                   'Hookload': 'hookload',\n",
    "                   'Pump Pressure': 'pump_press',\n",
    "                   'Return Flow': 'flow_out',\n",
    "                   'Flow In': 'flow_in',\n",
    "                   'Top Drive Torque': 'td_torque',\n",
    "                   'Gamma Measured while Drilling': 'gamma',\n",
    "                   'Rig Mode': 'rig_mode',\n",
    "                   'On Bottom': 'on_bottom_status',\n",
    "                   'Total Strokes per Minute': 'total_spm'\n",
    "                   }, inplace=True)\n",
    "print(df.columns)  # Check the columns in the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3674f43",
   "metadata": {},
   "source": [
    "We're ready to start our analysis.\n",
    "\n",
    "Let's wrap our heads around the dataset by visualizing a common DVD curve using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c15006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "df = df[['rig_time', 'md', 'rop', 'wob', 'diff_press', 'td_rpm', 'td_torque',\n",
    "         'bit_rpm', 'block_height', 'inc', 'azi', 'bit_size', 'on_bottom_status']]\n",
    "df['rig_time'] = pd.to_datetime(df['rig_time'], errors='coerce')  # Convert to datetime\n",
    "# print(df.head(10))\n",
    "\n",
    "# reduce df to take every 12th row\n",
    "plot_df = df.copy()\n",
    "plot_df = plot_df.iloc[::240, :]  # Take every 12th row\n",
    "plot_df.sort_values(by='rig_time', inplace=True)  # Sort by rig_time\n",
    "# drop rows where rig_time or md is null\n",
    "plot_df.dropna(subset=['rig_time', 'md'], inplace=True)\n",
    "# set rig_time as datetime\n",
    "plot_df['rig_time'] = pd.to_datetime(plot_df['rig_time'], errors='coerce')  # Convert to datetime\n",
    "plot_df['rig_time'] = plot_df['rig_time'].dt.strftime('%Y-%m-%d %H:%M:%S')  # Format datetime\n",
    "\n",
    "# convert md to numeric\n",
    "plot_df['md'] = pd.to_numeric(plot_df['md'], errors='coerce')\n",
    "\n",
    "print(f'Reduced row count: {plot_df.shape[0]}')  # Check the number of rows after reduction\n",
    "\n",
    "# Ensure plots are displayed in Jupyter Notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# plot line graph x axis = rig_time, y axis = bit_depth, then invert the y-axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(plot_df['rig_time'], plot_df['md'], label='Bit Depth', color='blue')\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis\n",
    "plt.xlabel('Rig Time')  # Set x-label\n",
    "plt.ylabel('Depth (ft)')  # Set y-label\n",
    "plt.title('DvD Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dba532",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_btm_plot_df = plot_df[plot_df['on_bottom_status'] == 1]  # Filter the data frame to show only data while bit is on-bottom (on_bottom_status = 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(on_btm_plot_df['rig_time'], on_btm_plot_df['md'], label='On Bottom', color='red')\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis\n",
    "plt.xlabel('Rig Time')  # Set x-label\n",
    "plt.ylabel('Depth (ft)')  # Set y-label\n",
    "plt.title('On Bottom DvD Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e7235f",
   "metadata": {},
   "source": [
    "## Fix rig_time to show accurate time stamps\n",
    "The rig time is duplicated across every minute's worth of data.\n",
    "Let's fix this with a quick script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd1cb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_btm_df = df[df['on_bottom_status'] == 1].copy()  \n",
    "group_mins_df = on_btm_df.groupby('rig_time')\n",
    "for name, group in group_mins_df:\n",
    "    # check if the group contains 6 rows\n",
    "    if len(group) == 6:\n",
    "        for index, row in group.iterrows():\n",
    "            # if the row is the first row, continue, else add 10 seconds to the previous row's time\n",
    "            if index == group.index[0]:\n",
    "                continue\n",
    "            else:\n",
    "                on_btm_df.at[index, 'rig_time'] = on_btm_df.loc[group.index[0], 'rig_time'] + pd.Timedelta(seconds=10 * (index - group.index[0]))\n",
    "# print(on_btm_df[['rig_time']].head(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553a4cd8",
   "metadata": {},
   "source": [
    "## Identify Unique Bit Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a549e436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set rig_time as datetime\n",
    "on_btm_df['rig_time'] = pd.to_datetime(on_btm_df['rig_time'], errors='coerce')  # Convert to datetime\n",
    "on_btm_df['rig_time_delta'] = on_btm_df['rig_time'].diff()  # Calculate the time difference between rows\n",
    "on_btm_df['rig_time_delta'] = on_btm_df['rig_time_delta'].dt.total_seconds() / 3600  # Convert time difference to seconds\n",
    "on_btm_df['md_delta'] = on_btm_df['md'].diff()  # Calculate the depth difference between rows\n",
    "\n",
    "run_number = 1\n",
    "# each time the time difference is greater than 5, increment the run_number by 1\n",
    "for index, row in on_btm_df.iterrows():\n",
    "    if row['rig_time_delta'] > 10:\n",
    "        run_number += 1\n",
    "    on_btm_df.at[index, 'run_number'] = run_number\n",
    "# get the start and end time for each run_number\n",
    "start_end_times_df = on_btm_df.groupby('run_number')['rig_time'].agg(['min', 'max']).reset_index()\n",
    "start_end_times_df.rename(columns={'min': 'start_time', 'max': 'end_time'}, inplace=True)\n",
    "start_end_times_df['run_duration'] = (start_end_times_df['end_time'] - start_end_times_df['start_time']).dt.total_seconds() / 3600  # Calculate the duration of each run in hours\n",
    "# Get the start and end depths for each run\n",
    "start_end_md_df = on_btm_df.groupby('run_number')['md'].agg(['min', 'max']).reset_index()\n",
    "start_end_md_df.rename(columns={'min': 'start_depth', 'max': 'end_depth'}, inplace=True)\n",
    "start_end_md_df['run_length'] = start_end_md_df['end_depth'] - start_end_md_df['start_depth']  # Calculate the length of each run\n",
    "# Merge the start and end times with the start and end depths\n",
    "bit_run_df = pd.merge(start_end_times_df, start_end_md_df, on='run_number')\n",
    "bit_run_df.rename(columns={'min': 'start_depth', 'max': 'end_depth'}, inplace=True)\n",
    "# reduce bit_run_df to only show runs greater than 1 hour and (gt 100 feet, lt 10000 feet)\n",
    "bit_run_df = bit_run_df[(bit_run_df['run_duration'] > 1) & (bit_run_df['run_length'] > 100) & (bit_run_df['run_length'] < 10000)]\n",
    "print(bit_run_df)  # Display the start and end times for each run_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f8b0c6",
   "metadata": {},
   "source": [
    "# Plot DVD Curve Color Coded by Run Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34738285",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df['run_number'] = 0  # Initialize a new column for run_number\n",
    "plot_df['rig_time'] = pd.to_datetime(plot_df['rig_time'], errors='coerce')  # Convert to datetime\n",
    "# Assign run_number to plot_df based on the run_number in on_btm_df\n",
    "for index, row in bit_run_df.iterrows():\n",
    "    plot_df.loc[(plot_df['rig_time'] >= row['start_time']) & (plot_df['rig_time'] <= row['end_time']), 'run_number'] = row['run_number']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(plot_df['rig_time'], plot_df['md'], c=plot_df['run_number'], cmap='viridis', label='Run Number')\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis\n",
    "plt.xlabel('Rig Time')  # Set x-label\n",
    "plt.ylabel('Depth (ft)')  # Set y-label\n",
    "plt.title('DvD Curve with Run Number')\n",
    "plt.colorbar(label='Run Number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fbe926",
   "metadata": {},
   "source": [
    "## Data Transformation & KPI Calculation\n",
    "Now, let's transform data and calculate key performance indicators (KPIs).\n",
    "\n",
    "First, we will create a calculated column: 'Depth of Cut' using ROP and Bit RPM.\n",
    "\n",
    "**Formula**\n",
    "\n",
    "depth_of_cut = 0.2 * rop / bit_rpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d825456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_btm_df['depth_of_cut'] = 0\n",
    "\n",
    "on_btm_df.loc[on_btm_df.bit_rpm > 10, 'depth_of_cut'] = (0.2) * on_btm_df['rop'] / on_btm_df['bit_rpm']\n",
    "\n",
    "print(f'ROP stats: \\n{on_btm_df.loc[(on_btm_df.rop < 1000) & (on_btm_df.rop > 0), 'rop'].describe()}\\n')  # Display ROP statistics\n",
    "print(f'Bit RPM stats: \\n{on_btm_df.loc[on_btm_df.bit_rpm > 0, \"bit_rpm\"].describe()}\\n')  # Display bit RPM statistics\n",
    "\n",
    "\n",
    "print(f'Depth of Cut Stats: \\n{on_btm_df.loc[on_btm_df.on_bottom_status == 1, \"depth_of_cut\"].describe()}\\n')  # Display depth of cut statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ee66d9",
   "metadata": {},
   "source": [
    "### Add the run numbers to the \"On Bottom\" Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f19b99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge run_number from start_end_times_df into on_btm_df\n",
    "on_btm_df['run_number'] = 0  # Initialize a new column for run_number\n",
    "for index, row in bit_run_df.iterrows():\n",
    "    on_btm_df.loc[(on_btm_df['rig_time'] >= row['start_time']) & (on_btm_df['rig_time'] <= row['end_time']), 'run_number'] = row['run_number']\n",
    "on_btm_df.loc[on_btm_df.run_number == 0, 'run_number'] = None  # Set run_number to None where it is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae1ebfe",
   "metadata": {},
   "source": [
    "Now let's calculate KPIs across each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f788e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate KPIs for each bit_size, when on_bottom is True\n",
    "group_df = on_btm_df.groupby(['run_number'])\n",
    "\n",
    "# print(f'\\n{group_df.size()}')\n",
    "for name, group in group_df:\n",
    "    print(f'\\nRun Number: {name}')\n",
    "    print(group[['rop', 'wob', 'td_rpm', 'td_torque', 'depth_of_cut']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5190711",
   "metadata": {},
   "source": [
    "Now let's check for any ROP outliers and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ce882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for ROP outliers and remove them from group_df\n",
    "print(group_df.reset_index(inplace=True))\n",
    "filtered_group_df = group_df.filter(lambda x: x['rop'].between(x['rop'].quantile(0.05), x['rop'].quantile(0.95)).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d862b2",
   "metadata": {},
   "source": [
    "## Data Visualization with Matplotlib & Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7436c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Plot a bar chart of ROP for each run number in group_df\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='run_number', y='rop', data=group_df)\n",
    "plt.xlabel('Run Number')  # Set x-label\n",
    "plt.ylabel('ROP (ft/hr)')  # Set y-label\n",
    "plt.title('ROP by Run')\n",
    "# overlay a line plot of the run_length for each run_number\n",
    "# plt.twinx()\n",
    "# sns.lineplot(x='run_number', y='run_length', data=bit_run_df, color='red')\n",
    "# plt.ylabel('Run Length (ft)')  # Set y-label for the line plot\n",
    "# plt.legend(['Run Length', 'ROP'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09e53ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot Example\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.scatterplot(x='Depth', y='MSE', data=df)\n",
    "plt.title('MSE vs Depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5ef5c2",
   "metadata": {},
   "source": [
    "## Final Exercise\n",
    "Try the following:\n",
    "1. Create a new DataFrame with Well Name, Depth, and ROP.\n",
    "2. Upload a CSV file and explore the data.\n",
    "3. Merge two DataFrames with a common column.\n",
    "4. Create a scatterplot of Depth vs ROP.\n",
    "\n",
    "**Congratulations on completing Module 1!** 🎉"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
